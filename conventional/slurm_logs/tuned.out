Removing conda
Loading conda
🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.
🦥 Unsloth Zoo will now patch everything to make training faster!
INFO 05-08 11:20:48 [importing.py:53] Triton module has been replaced with a placeholder.
INFO 05-08 11:20:48 [__init__.py:239] Automatically detected platform cuda.
Unsloth 2025.4.3 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.
Thu May  8 11:20:52 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A40                     On  |   00000000:65:00.0 Off |                    0 |
|  0%   34C    P0             79W /  300W |     269MiB /  46068MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A    792155      C   python                                        260MiB |
+-----------------------------------------------------------------------------------------+

INFO: PyTorch Version: 2.6.0+cu124
INFO: CUDA Version: 12.4
INFO: cuDNN Version: 90100
INFO: CUDA Available: True
INFO: GPU Count: 1
INFO: Training: True, Epochs: 5, Batch Size: 64, Learning Rate: 0.001
==((====))==  Unsloth 2025.4.3: Fast Llama patching. Transformers: 4.51.3. vLLM: 0.8.5.
   \\   /|    NVIDIA A40. Num GPUs = 1. Max memory: 44.339 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.6.0+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.2.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
INFO: Model loaded
INFO: First 25 of 32 layers frozen. Rest are trainable.
INFO: QLora applied
INFO: Loaded dataset of 690 samples
INFO: Max prompted length:992
Map (num_proc=2):   0%|          | 0/621 [00:00<?, ? examples/s]Map (num_proc=2):  50%|█████     | 311/621 [00:01<00:01, 256.48 examples/s]Map (num_proc=2): 100%|██████████| 621/621 [00:01<00:00, 544.99 examples/s]Map (num_proc=2): 100%|██████████| 621/621 [00:01<00:00, 433.98 examples/s]
Map (num_proc=2):   0%|          | 0/69 [00:00<?, ? examples/s]Map (num_proc=2):  51%|█████     | 35/69 [00:00<00:00, 43.66 examples/s]Map (num_proc=2): 100%|██████████| 69/69 [00:00<00:00, 83.77 examples/s]Map (num_proc=2): 100%|██████████| 69/69 [00:01<00:00, 66.69 examples/s]
INFO: Configured
  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:01<00:00,  1.50it/s]100%|██████████| 2/2 [00:01<00:00,  1.41it/s]
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 621 | Num Epochs = 5 | Total steps = 50
O^O/ \_/ \    Batch size per device = 64 | Gradient accumulation steps = 1
\        /    Data Parallel GPUs = 1 | Total batch size (64 x 1 x 1) = 64
 "-____-"     Trainable parameters = 83,886,080/8,000,000,000 (1.05% trained)
cleaned cache post eval

Test Loss: 1.8037934303283691
  0%|          | 0/50 [00:00<?, ?it/s]  2%|▏         | 1/50 [00:46<37:46, 46.25s/it]                                                2%|▏         | 1/50 [00:46<37:46, 46.25s/it]  4%|▍         | 2/50 [01:20<31:35, 39.48s/it]  6%|▌         | 3/50 [01:55<28:58, 36.98s/it]  8%|▊         | 4/50 [02:29<27:39, 36.08s/it] 10%|█         | 5/50 [03:03<26:21, 35.15s/it] 12%|█▏        | 6/50 [03:40<26:13, 35.76s/it] 14%|█▍        | 7/50 [04:13<25:00, 34.89s/it] 16%|█▌        | 8/50 [04:46<24:02, 34.35s/it] 18%|█▊        | 9/50 [05:19<23:10, 33.92s/it] 20%|██        | 10/50 [05:42<20:28, 30.71s/it]                                                20%|██        | 10/50 [05:43<20:28, 30.71s/it]{'loss': 1.807, 'grad_norm': 0.6460870504379272, 'learning_rate': 0.0, 'epoch': 0.1}
Unsloth: Will smartly offload gradients to save VRAM!
Cache cleared after epoch

{'loss': 0.7795, 'grad_norm': 0.14950376749038696, 'learning_rate': 0.0009111111111111111, 'epoch': 1.0}

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|██████████| 2/2 [00:01<00:00,  1.08it/s][A                                               
                                             [A 20%|██        | 10/50 [06:01<20:28, 30.71s/it]
100%|██████████| 2/2 [00:01<00:00,  1.08it/s][A
                                             [A 22%|██▏       | 11/50 [06:41<25:32, 39.28s/it] 24%|██▍       | 12/50 [07:14<23:35, 37.25s/it] 26%|██▌       | 13/50 [07:47<22:10, 35.96s/it] 28%|██▊       | 14/50 [08:20<21:00, 35.01s/it] 30%|███       | 15/50 [08:53<20:07, 34.49s/it] 32%|███▏      | 16/50 [09:26<19:19, 34.11s/it] 34%|███▍      | 17/50 [09:59<18:31, 33.67s/it] 36%|███▌      | 18/50 [10:31<17:47, 33.34s/it] 38%|███▊      | 19/50 [11:04<17:08, 33.19s/it] 40%|████      | 20/50 [11:27<15:02, 30.07s/it]                                                40%|████      | 20/50 [11:27<15:02, 30.07s/it]{'eval_loss': 0.16520385444164276, 'eval_model_preparation_time': 0.0217, 'eval_runtime': 18.3814, 'eval_samples_per_second': 3.754, 'eval_steps_per_second': 0.109, 'epoch': 1.0}
cleaned cache post eval

Cache cleared after epoch

{'loss': 0.1749, 'grad_norm': 0.07091374695301056, 'learning_rate': 0.000688888888888889, 'epoch': 2.0}

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|██████████| 2/2 [00:01<00:00,  1.08it/s][A                                               
                                             [A 40%|████      | 20/50 [11:45<15:02, 30.07s/it]
100%|██████████| 2/2 [00:01<00:00,  1.08it/s][A
                                             [A 42%|████▏     | 21/50 [12:21<17:57, 37.16s/it] 44%|████▍     | 22/50 [12:54<16:47, 35.97s/it] 46%|████▌     | 23/50 [13:26<15:44, 34.96s/it] 48%|████▊     | 24/50 [13:59<14:51, 34.30s/it] 50%|█████     | 25/50 [14:32<14:06, 33.88s/it] 52%|█████▏    | 26/50 [15:05<13:23, 33.49s/it] 54%|█████▍    | 27/50 [15:38<12:48, 33.40s/it] 56%|█████▌    | 28/50 [16:11<12:10, 33.20s/it] 58%|█████▊    | 29/50 [16:44<11:37, 33.21s/it] 60%|██████    | 30/50 [17:07<10:01, 30.09s/it]                                                60%|██████    | 30/50 [17:07<10:01, 30.09s/it]{'eval_loss': 0.15360841155052185, 'eval_model_preparation_time': 0.0217, 'eval_runtime': 18.0618, 'eval_samples_per_second': 3.82, 'eval_steps_per_second': 0.111, 'epoch': 2.0}
cleaned cache post eval

Cache cleared after epoch

{'loss': 0.1522, 'grad_norm': 0.04366476461291313, 'learning_rate': 0.00046666666666666666, 'epoch': 3.0}

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|██████████| 2/2 [00:01<00:00,  1.07it/s][A                                               
                                             [A 60%|██████    | 30/50 [17:25<10:01, 30.09s/it]
100%|██████████| 2/2 [00:01<00:00,  1.07it/s][A
                                             [A 62%|██████▏   | 31/50 [17:59<11:41, 36.92s/it] 64%|██████▍   | 32/50 [18:33<10:44, 35.79s/it] 66%|██████▌   | 33/50 [19:06<09:57, 35.14s/it] 68%|██████▊   | 34/50 [19:40<09:13, 34.60s/it] 70%|███████   | 35/50 [20:12<08:30, 34.04s/it] 72%|███████▏  | 36/50 [20:45<07:51, 33.69s/it] 74%|███████▍  | 37/50 [21:18<07:14, 33.40s/it] 76%|███████▌  | 38/50 [21:51<06:37, 33.16s/it] 78%|███████▊  | 39/50 [22:23<06:03, 33.02s/it] 80%|████████  | 40/50 [22:46<04:59, 29.93s/it]                                                80%|████████  | 40/50 [22:46<04:59, 29.93s/it]{'eval_loss': 0.1494046002626419, 'eval_model_preparation_time': 0.0217, 'eval_runtime': 18.1101, 'eval_samples_per_second': 3.81, 'eval_steps_per_second': 0.11, 'epoch': 3.0}
cleaned cache post eval

Cache cleared after epoch

{'loss': 0.146, 'grad_norm': 0.037421852350234985, 'learning_rate': 0.00024444444444444443, 'epoch': 4.0}

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|██████████| 2/2 [00:01<00:00,  1.08it/s][A                                               
                                             [A 80%|████████  | 40/50 [23:04<04:59, 29.93s/it]
100%|██████████| 2/2 [00:01<00:00,  1.08it/s][A
                                             [A 82%|████████▏ | 41/50 [23:39<05:30, 36.75s/it] 84%|████████▍ | 42/50 [24:12<04:45, 35.66s/it] 86%|████████▌ | 43/50 [24:45<04:03, 34.81s/it] 88%|████████▊ | 44/50 [25:18<03:26, 34.34s/it] 90%|█████████ | 45/50 [25:50<02:48, 33.79s/it] 92%|█████████▏| 46/50 [26:23<02:14, 33.50s/it] 94%|█████████▍| 47/50 [26:56<01:39, 33.22s/it] 96%|█████████▌| 48/50 [27:29<01:06, 33.32s/it] 98%|█████████▊| 49/50 [28:02<00:33, 33.12s/it]100%|██████████| 50/50 [28:25<00:00, 30.01s/it]                                               100%|██████████| 50/50 [28:25<00:00, 30.01s/it]{'eval_loss': 0.14760805666446686, 'eval_model_preparation_time': 0.0217, 'eval_runtime': 18.0849, 'eval_samples_per_second': 3.815, 'eval_steps_per_second': 0.111, 'epoch': 4.0}
cleaned cache post eval

Cache cleared after epoch

{'loss': 0.1421, 'grad_norm': 0.03222475200891495, 'learning_rate': 2.2222222222222223e-05, 'epoch': 5.0}

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|██████████| 2/2 [00:01<00:00,  1.08it/s][A                                               
                                             [A100%|██████████| 50/50 [28:43<00:00, 30.01s/it]
100%|██████████| 2/2 [00:01<00:00,  1.08it/s][A
                                             [A                                               100%|██████████| 50/50 [28:47<00:00, 30.01s/it]100%|██████████| 50/50 [28:47<00:00, 34.55s/it]
{'eval_loss': 0.14753325283527374, 'eval_model_preparation_time': 0.0217, 'eval_runtime': 18.0731, 'eval_samples_per_second': 3.818, 'eval_steps_per_second': 0.111, 'epoch': 5.0}
cleaned cache post eval

{'train_runtime': 1727.4312, 'train_samples_per_second': 1.797, 'train_steps_per_second': 0.029, 'train_loss': 0.2994892692565918, 'epoch': 5.0}
cleaned cache post train

INFO: Trained model
  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:01<00:00,  1.08it/s]100%|██████████| 2/2 [00:01<00:00,  1.01it/s]
cleaned cache post eval

Test Loss: 0.14753322303295135
  0%|          | 0/69 [00:00<?, ?it/s]  1%|▏         | 1/69 [00:04<05:32,  4.89s/it]  3%|▎         | 2/69 [00:09<05:20,  4.79s/it]  4%|▍         | 3/69 [00:15<05:49,  5.29s/it]  6%|▌         | 4/69 [00:21<05:57,  5.49s/it]  7%|▋         | 5/69 [00:26<05:33,  5.22s/it]  9%|▊         | 6/69 [00:30<05:18,  5.05s/it] 10%|█         | 7/69 [00:35<05:06,  4.94s/it] 12%|█▏        | 8/69 [00:40<04:57,  4.87s/it] 13%|█▎        | 9/69 [00:44<04:49,  4.82s/it] 14%|█▍        | 10/69 [00:50<04:55,  5.01s/it] 16%|█▌        | 11/69 [00:56<05:15,  5.45s/it] 17%|█▋        | 12/69 [01:01<04:57,  5.23s/it] 19%|█▉        | 13/69 [01:06<04:44,  5.08s/it] 20%|██        | 14/69 [01:10<04:33,  4.97s/it] 22%|██▏       | 15/69 [01:15<04:24,  4.90s/it] 23%|██▎       | 16/69 [01:20<04:16,  4.85s/it] 25%|██▍       | 17/69 [01:26<04:24,  5.08s/it] 26%|██▌       | 18/69 [01:32<04:40,  5.50s/it] 28%|██▊       | 19/69 [01:37<04:23,  5.27s/it] 29%|██▉       | 20/69 [01:41<04:10,  5.10s/it] 30%|███       | 21/69 [01:46<03:59,  4.99s/it] 32%|███▏      | 22/69 [01:51<03:50,  4.91s/it] 33%|███▎      | 23/69 [01:56<03:43,  4.85s/it] 35%|███▍      | 24/69 [02:01<03:48,  5.09s/it] 36%|███▌      | 25/69 [02:08<04:02,  5.51s/it] 38%|███▊      | 26/69 [02:12<03:46,  5.27s/it] 39%|███▉      | 27/69 [02:17<03:34,  5.10s/it] 41%|████      | 28/69 [02:22<03:24,  4.99s/it] 42%|████▏     | 29/69 [02:27<03:16,  4.91s/it] 43%|████▎     | 30/69 [02:31<03:09,  4.85s/it] 45%|████▍     | 31/69 [02:37<03:13,  5.08s/it] 46%|████▋     | 32/69 [02:43<03:23,  5.50s/it] 48%|████▊     | 33/69 [02:48<03:09,  5.27s/it] 49%|████▉     | 34/69 [02:53<02:58,  5.11s/it] 51%|█████     | 35/69 [02:58<02:49,  5.00s/it] 52%|█████▏    | 36/69 [03:02<02:42,  4.92s/it] 54%|█████▎    | 37/69 [03:07<02:35,  4.86s/it] 55%|█████▌    | 38/69 [03:13<02:37,  5.09s/it] 57%|█████▋    | 39/69 [03:19<02:45,  5.51s/it] 58%|█████▊    | 40/69 [03:24<02:33,  5.28s/it] 59%|█████▉    | 41/69 [03:29<02:23,  5.11s/it] 61%|██████    | 42/69 [03:33<02:15,  5.00s/it] 62%|██████▏   | 43/69 [03:38<02:08,  4.92s/it] 64%|██████▍   | 44/69 [03:43<02:04,  5.00s/it] 65%|██████▌   | 45/69 [03:48<02:00,  5.03s/it] 67%|██████▋   | 46/69 [03:54<02:02,  5.33s/it] 68%|██████▊   | 47/69 [04:00<01:58,  5.39s/it] 70%|██████▉   | 48/69 [04:05<01:53,  5.41s/it] 71%|███████   | 49/69 [04:10<01:44,  5.22s/it] 72%|███████▏  | 50/69 [04:15<01:37,  5.11s/it] 74%|███████▍  | 51/69 [04:20<01:29,  5.00s/it] 75%|███████▌  | 52/69 [04:25<01:23,  4.92s/it] 77%|███████▋  | 53/69 [04:30<01:23,  5.19s/it] 78%|███████▊  | 54/69 [04:36<01:21,  5.46s/it] 80%|███████▉  | 55/69 [04:42<01:14,  5.34s/it] 81%|████████  | 56/69 [04:46<01:07,  5.16s/it] 83%|████████▎ | 57/69 [04:51<01:00,  5.02s/it] 84%|████████▍ | 58/69 [04:56<00:54,  4.93s/it] 86%|████████▌ | 59/69 [05:00<00:48,  4.87s/it] 87%|████████▋ | 60/69 [05:06<00:45,  5.05s/it] 88%|████████▊ | 61/69 [05:13<00:44,  5.57s/it] 90%|████████▉ | 62/69 [05:17<00:37,  5.32s/it] 91%|█████████▏| 63/69 [05:22<00:30,  5.14s/it] 93%|█████████▎| 64/69 [05:27<00:25,  5.03s/it] 94%|█████████▍| 65/69 [05:32<00:19,  4.94s/it] 96%|█████████▌| 66/69 [05:36<00:14,  4.87s/it] 97%|█████████▋| 67/69 [05:41<00:09,  4.95s/it] 99%|█████████▊| 68/69 [05:49<00:05,  5.62s/it]100%|██████████| 69/69 [05:53<00:00,  5.35s/it]100%|██████████| 69/69 [05:53<00:00,  5.13s/it]
INFO: Inference complete
