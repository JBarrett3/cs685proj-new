Removing conda
Loading conda
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
INFO 05-08 11:20:48 [importing.py:53] Triton module has been replaced with a placeholder.
INFO 05-08 11:20:48 [__init__.py:239] Automatically detected platform cuda.
Unsloth 2025.4.3 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.
Thu May  8 11:20:52 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A40                     On  |   00000000:65:00.0 Off |                    0 |
|  0%   34C    P0             79W /  300W |     269MiB /  46068MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A    792155      C   python                                        260MiB |
+-----------------------------------------------------------------------------------------+

INFO: PyTorch Version: 2.6.0+cu124
INFO: CUDA Version: 12.4
INFO: cuDNN Version: 90100
INFO: CUDA Available: True
INFO: GPU Count: 1
INFO: Training: True, Epochs: 5, Batch Size: 64, Learning Rate: 0.001
==((====))==  Unsloth 2025.4.3: Fast Llama patching. Transformers: 4.51.3. vLLM: 0.8.5.
   \\   /|    NVIDIA A40. Num GPUs = 1. Max memory: 44.339 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.6.0+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.2.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
INFO: Model loaded
INFO: First 25 of 32 layers frozen. Rest are trainable.
INFO: QLora applied
INFO: Loaded dataset of 690 samples
INFO: Max prompted length:992
Map (num_proc=2):   0%|          | 0/621 [00:00<?, ? examples/s]Map (num_proc=2):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 311/621 [00:01<00:01, 256.48 examples/s]Map (num_proc=2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 621/621 [00:01<00:00, 544.99 examples/s]Map (num_proc=2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 621/621 [00:01<00:00, 433.98 examples/s]
Map (num_proc=2):   0%|          | 0/69 [00:00<?, ? examples/s]Map (num_proc=2):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 35/69 [00:00<00:00, 43.66 examples/s]Map (num_proc=2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:00<00:00, 83.77 examples/s]Map (num_proc=2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:01<00:00, 66.69 examples/s]
INFO: Configured
  0%|          | 0/2 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.50it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.41it/s]
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 621 | Num Epochs = 5 | Total steps = 50
O^O/ \_/ \    Batch size per device = 64 | Gradient accumulation steps = 1
\        /    Data Parallel GPUs = 1 | Total batch size (64 x 1 x 1) = 64
 "-____-"     Trainable parameters = 83,886,080/8,000,000,000 (1.05% trained)
cleaned cache post eval

Test Loss: 1.8037934303283691
  0%|          | 0/50 [00:00<?, ?it/s]  2%|â–         | 1/50 [00:46<37:46, 46.25s/it]                                                2%|â–         | 1/50 [00:46<37:46, 46.25s/it]  4%|â–         | 2/50 [01:20<31:35, 39.48s/it]  6%|â–Œ         | 3/50 [01:55<28:58, 36.98s/it]  8%|â–Š         | 4/50 [02:29<27:39, 36.08s/it] 10%|â–ˆ         | 5/50 [03:03<26:21, 35.15s/it] 12%|â–ˆâ–        | 6/50 [03:40<26:13, 35.76s/it] 14%|â–ˆâ–        | 7/50 [04:13<25:00, 34.89s/it] 16%|â–ˆâ–Œ        | 8/50 [04:46<24:02, 34.35s/it] 18%|â–ˆâ–Š        | 9/50 [05:19<23:10, 33.92s/it] 20%|â–ˆâ–ˆ        | 10/50 [05:42<20:28, 30.71s/it]                                                20%|â–ˆâ–ˆ        | 10/50 [05:43<20:28, 30.71s/it]{'loss': 1.807, 'grad_norm': 0.6460870504379272, 'learning_rate': 0.0, 'epoch': 0.1}
Unsloth: Will smartly offload gradients to save VRAM!
Cache cleared after epoch

{'loss': 0.7795, 'grad_norm': 0.14950376749038696, 'learning_rate': 0.0009111111111111111, 'epoch': 1.0}

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.08it/s][A                                               
                                             [A 20%|â–ˆâ–ˆ        | 10/50 [06:01<20:28, 30.71s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.08it/s][A
                                             [A 22%|â–ˆâ–ˆâ–       | 11/50 [06:41<25:32, 39.28s/it] 24%|â–ˆâ–ˆâ–       | 12/50 [07:14<23:35, 37.25s/it] 26%|â–ˆâ–ˆâ–Œ       | 13/50 [07:47<22:10, 35.96s/it] 28%|â–ˆâ–ˆâ–Š       | 14/50 [08:20<21:00, 35.01s/it] 30%|â–ˆâ–ˆâ–ˆ       | 15/50 [08:53<20:07, 34.49s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 16/50 [09:26<19:19, 34.11s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 17/50 [09:59<18:31, 33.67s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/50 [10:31<17:47, 33.34s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 19/50 [11:04<17:08, 33.19s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [11:27<15:02, 30.07s/it]                                                40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [11:27<15:02, 30.07s/it]{'eval_loss': 0.16520385444164276, 'eval_model_preparation_time': 0.0217, 'eval_runtime': 18.3814, 'eval_samples_per_second': 3.754, 'eval_steps_per_second': 0.109, 'epoch': 1.0}
cleaned cache post eval

Cache cleared after epoch

{'loss': 0.1749, 'grad_norm': 0.07091374695301056, 'learning_rate': 0.000688888888888889, 'epoch': 2.0}

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.08it/s][A                                               
                                             [A 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [11:45<15:02, 30.07s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.08it/s][A
                                             [A 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/50 [12:21<17:57, 37.16s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/50 [12:54<16:47, 35.97s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/50 [13:26<15:44, 34.96s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 24/50 [13:59<14:51, 34.30s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [14:32<14:06, 33.88s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/50 [15:05<13:23, 33.49s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 27/50 [15:38<12:48, 33.40s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 28/50 [16:11<12:10, 33.20s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 29/50 [16:44<11:37, 33.21s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [17:07<10:01, 30.09s/it]                                                60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [17:07<10:01, 30.09s/it]{'eval_loss': 0.15360841155052185, 'eval_model_preparation_time': 0.0217, 'eval_runtime': 18.0618, 'eval_samples_per_second': 3.82, 'eval_steps_per_second': 0.111, 'epoch': 2.0}
cleaned cache post eval

Cache cleared after epoch

{'loss': 0.1522, 'grad_norm': 0.04366476461291313, 'learning_rate': 0.00046666666666666666, 'epoch': 3.0}

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.07it/s][A                                               
                                             [A 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [17:25<10:01, 30.09s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.07it/s][A
                                             [A 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/50 [17:59<11:41, 36.92s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 32/50 [18:33<10:44, 35.79s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 33/50 [19:06<09:57, 35.14s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 34/50 [19:40<09:13, 34.60s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [20:12<08:30, 34.04s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 36/50 [20:45<07:51, 33.69s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 37/50 [21:18<07:14, 33.40s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 38/50 [21:51<06:37, 33.16s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 39/50 [22:23<06:03, 33.02s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [22:46<04:59, 29.93s/it]                                                80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [22:46<04:59, 29.93s/it]{'eval_loss': 0.1494046002626419, 'eval_model_preparation_time': 0.0217, 'eval_runtime': 18.1101, 'eval_samples_per_second': 3.81, 'eval_steps_per_second': 0.11, 'epoch': 3.0}
cleaned cache post eval

Cache cleared after epoch

{'loss': 0.146, 'grad_norm': 0.037421852350234985, 'learning_rate': 0.00024444444444444443, 'epoch': 4.0}

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.08it/s][A                                               
                                             [A 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [23:04<04:59, 29.93s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.08it/s][A
                                             [A 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 41/50 [23:39<05:30, 36.75s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/50 [24:12<04:45, 35.66s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 43/50 [24:45<04:03, 34.81s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 44/50 [25:18<03:26, 34.34s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [25:50<02:48, 33.79s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 46/50 [26:23<02:14, 33.50s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/50 [26:56<01:39, 33.22s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 48/50 [27:29<01:06, 33.32s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 49/50 [28:02<00:33, 33.12s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [28:25<00:00, 30.01s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [28:25<00:00, 30.01s/it]{'eval_loss': 0.14760805666446686, 'eval_model_preparation_time': 0.0217, 'eval_runtime': 18.0849, 'eval_samples_per_second': 3.815, 'eval_steps_per_second': 0.111, 'epoch': 4.0}
cleaned cache post eval

Cache cleared after epoch

{'loss': 0.1421, 'grad_norm': 0.03222475200891495, 'learning_rate': 2.2222222222222223e-05, 'epoch': 5.0}

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.08it/s][A                                               
                                             [A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [28:43<00:00, 30.01s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.08it/s][A
                                             [A                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [28:47<00:00, 30.01s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [28:47<00:00, 34.55s/it]
{'eval_loss': 0.14753325283527374, 'eval_model_preparation_time': 0.0217, 'eval_runtime': 18.0731, 'eval_samples_per_second': 3.818, 'eval_steps_per_second': 0.111, 'epoch': 5.0}
cleaned cache post eval

{'train_runtime': 1727.4312, 'train_samples_per_second': 1.797, 'train_steps_per_second': 0.029, 'train_loss': 0.2994892692565918, 'epoch': 5.0}
cleaned cache post train

INFO: Trained model
  0%|          | 0/2 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.01it/s]
cleaned cache post eval

Test Loss: 0.14753322303295135
  0%|          | 0/69 [00:00<?, ?it/s]  1%|â–         | 1/69 [00:04<05:32,  4.89s/it]  3%|â–Ž         | 2/69 [00:09<05:20,  4.79s/it]  4%|â–         | 3/69 [00:15<05:49,  5.29s/it]  6%|â–Œ         | 4/69 [00:21<05:57,  5.49s/it]  7%|â–‹         | 5/69 [00:26<05:33,  5.22s/it]  9%|â–Š         | 6/69 [00:30<05:18,  5.05s/it] 10%|â–ˆ         | 7/69 [00:35<05:06,  4.94s/it] 12%|â–ˆâ–        | 8/69 [00:40<04:57,  4.87s/it] 13%|â–ˆâ–Ž        | 9/69 [00:44<04:49,  4.82s/it] 14%|â–ˆâ–        | 10/69 [00:50<04:55,  5.01s/it] 16%|â–ˆâ–Œ        | 11/69 [00:56<05:15,  5.45s/it] 17%|â–ˆâ–‹        | 12/69 [01:01<04:57,  5.23s/it] 19%|â–ˆâ–‰        | 13/69 [01:06<04:44,  5.08s/it] 20%|â–ˆâ–ˆ        | 14/69 [01:10<04:33,  4.97s/it] 22%|â–ˆâ–ˆâ–       | 15/69 [01:15<04:24,  4.90s/it] 23%|â–ˆâ–ˆâ–Ž       | 16/69 [01:20<04:16,  4.85s/it] 25%|â–ˆâ–ˆâ–       | 17/69 [01:26<04:24,  5.08s/it] 26%|â–ˆâ–ˆâ–Œ       | 18/69 [01:32<04:40,  5.50s/it] 28%|â–ˆâ–ˆâ–Š       | 19/69 [01:37<04:23,  5.27s/it] 29%|â–ˆâ–ˆâ–‰       | 20/69 [01:41<04:10,  5.10s/it] 30%|â–ˆâ–ˆâ–ˆ       | 21/69 [01:46<03:59,  4.99s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 22/69 [01:51<03:50,  4.91s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 23/69 [01:56<03:43,  4.85s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 24/69 [02:01<03:48,  5.09s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 25/69 [02:08<04:02,  5.51s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 26/69 [02:12<03:46,  5.27s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 27/69 [02:17<03:34,  5.10s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 28/69 [02:22<03:24,  4.99s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 29/69 [02:27<03:16,  4.91s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 30/69 [02:31<03:09,  4.85s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31/69 [02:37<03:13,  5.08s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 32/69 [02:43<03:23,  5.50s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 33/69 [02:48<03:09,  5.27s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 34/69 [02:53<02:58,  5.11s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 35/69 [02:58<02:49,  5.00s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 36/69 [03:02<02:42,  4.92s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 37/69 [03:07<02:35,  4.86s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 38/69 [03:13<02:37,  5.09s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 39/69 [03:19<02:45,  5.51s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 40/69 [03:24<02:33,  5.28s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 41/69 [03:29<02:23,  5.11s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 42/69 [03:33<02:15,  5.00s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 43/69 [03:38<02:08,  4.92s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 44/69 [03:43<02:04,  5.00s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 45/69 [03:48<02:00,  5.03s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 46/69 [03:54<02:02,  5.33s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 47/69 [04:00<01:58,  5.39s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 48/69 [04:05<01:53,  5.41s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 49/69 [04:10<01:44,  5.22s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 50/69 [04:15<01:37,  5.11s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 51/69 [04:20<01:29,  5.00s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 52/69 [04:25<01:23,  4.92s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 53/69 [04:30<01:23,  5.19s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 54/69 [04:36<01:21,  5.46s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 55/69 [04:42<01:14,  5.34s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 56/69 [04:46<01:07,  5.16s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 57/69 [04:51<01:00,  5.02s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 58/69 [04:56<00:54,  4.93s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 59/69 [05:00<00:48,  4.87s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 60/69 [05:06<00:45,  5.05s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 61/69 [05:13<00:44,  5.57s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 62/69 [05:17<00:37,  5.32s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 63/69 [05:22<00:30,  5.14s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 64/69 [05:27<00:25,  5.03s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 65/69 [05:32<00:19,  4.94s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 66/69 [05:36<00:14,  4.87s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 67/69 [05:41<00:09,  4.95s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 68/69 [05:49<00:05,  5.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [05:53<00:00,  5.35s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [05:53<00:00,  5.13s/it]
INFO: Inference complete
