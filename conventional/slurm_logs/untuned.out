Removing conda
Loading conda
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
INFO 05-08 10:47:46 [importing.py:53] Triton module has been replaced with a placeholder.
INFO 05-08 10:47:46 [__init__.py:239] Automatically detected platform cuda.
Unsloth 2025.4.3 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.
Thu May  8 10:47:50 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A40                     On  |   00000000:65:00.0 Off |                    0 |
|  0%   34C    P0             79W /  300W |     269MiB /  46068MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A    785190      C   python                                        260MiB |
+-----------------------------------------------------------------------------------------+

INFO: PyTorch Version: 2.6.0+cu124
INFO: CUDA Version: 12.4
INFO: cuDNN Version: 90100
INFO: CUDA Available: True
INFO: GPU Count: 1
INFO: Training: False, Limit: -1, Epochs: 5, Batch Size: 64, Learning Rate: 0.001
==((====))==  Unsloth 2025.4.3: Fast Llama patching. Transformers: 4.51.3. vLLM: 0.8.5.
   \\   /|    NVIDIA A40. Num GPUs = 1. Max memory: 44.339 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.6.0+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.2.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
INFO: Model loaded
INFO: First 25 of 32 layers frozen. Rest are trainable.
INFO: QLora applied
INFO: Loaded dataset of 690 samples
INFO: Max prompted length:988
INFO: Configured
  0%|          | 0/2 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.40it/s]
cleaned cache post eval

Test Loss: 1.8093949556350708
INFO: Bypassing training
  0%|          | 0/2 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.01it/s]
cleaned cache post eval

Test Loss: 1.8093949556350708
  0%|          | 0/69 [00:00<?, ?it/s]  1%|â–         | 1/69 [00:04<05:32,  4.89s/it]  3%|â–Ž         | 2/69 [00:09<05:19,  4.77s/it]  4%|â–         | 3/69 [00:14<05:12,  4.73s/it]  6%|â–Œ         | 4/69 [00:18<05:06,  4.71s/it]  7%|â–‹         | 5/69 [00:23<05:01,  4.70s/it]  9%|â–Š         | 6/69 [00:28<04:56,  4.70s/it] 10%|â–ˆ         | 7/69 [00:33<04:51,  4.70s/it] 12%|â–ˆâ–        | 8/69 [00:37<04:46,  4.69s/it] 13%|â–ˆâ–Ž        | 9/69 [00:42<04:41,  4.69s/it] 14%|â–ˆâ–        | 10/69 [00:47<04:36,  4.69s/it] 16%|â–ˆâ–Œ        | 11/69 [00:51<04:32,  4.69s/it] 17%|â–ˆâ–‹        | 12/69 [00:56<04:27,  4.69s/it] 19%|â–ˆâ–‰        | 13/69 [01:01<04:22,  4.69s/it] 20%|â–ˆâ–ˆ        | 14/69 [01:05<04:17,  4.69s/it] 22%|â–ˆâ–ˆâ–       | 15/69 [01:10<04:13,  4.69s/it] 23%|â–ˆâ–ˆâ–Ž       | 16/69 [01:15<04:08,  4.69s/it] 25%|â–ˆâ–ˆâ–       | 17/69 [01:19<04:04,  4.69s/it] 26%|â–ˆâ–ˆâ–Œ       | 18/69 [01:24<03:59,  4.69s/it] 28%|â–ˆâ–ˆâ–Š       | 19/69 [01:29<03:54,  4.69s/it] 29%|â–ˆâ–ˆâ–‰       | 20/69 [01:34<03:49,  4.69s/it] 30%|â–ˆâ–ˆâ–ˆ       | 21/69 [01:38<03:45,  4.69s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 22/69 [01:43<03:40,  4.69s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 23/69 [01:48<03:35,  4.69s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 24/69 [01:52<03:31,  4.69s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 25/69 [01:57<03:26,  4.70s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 26/69 [02:02<03:21,  4.69s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 27/69 [02:06<03:17,  4.69s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 28/69 [02:11<03:12,  4.69s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 29/69 [02:16<03:07,  4.69s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 30/69 [02:20<03:03,  4.69s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31/69 [02:25<02:58,  4.71s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 32/69 [02:30<02:54,  4.70s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 33/69 [02:35<02:48,  4.69s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 34/69 [02:39<02:43,  4.68s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 35/69 [02:44<02:39,  4.68s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 36/69 [02:49<02:34,  4.68s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 37/69 [02:53<02:29,  4.68s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 38/69 [02:58<02:25,  4.69s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 39/69 [03:03<02:21,  4.71s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 40/69 [03:07<02:16,  4.71s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 41/69 [03:12<02:11,  4.71s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 42/69 [03:17<02:07,  4.71s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 43/69 [03:22<02:02,  4.71s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 44/69 [03:26<01:57,  4.71s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 45/69 [03:31<01:53,  4.71s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 46/69 [03:36<01:48,  4.71s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 47/69 [03:40<01:43,  4.71s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 48/69 [03:45<01:38,  4.71s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 49/69 [03:50<01:34,  4.71s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 50/69 [03:55<01:29,  4.71s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 51/69 [03:59<01:24,  4.71s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 52/69 [04:04<01:20,  4.71s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 53/69 [04:09<01:15,  4.71s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 54/69 [04:13<01:10,  4.72s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 55/69 [04:18<01:06,  4.72s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 56/69 [04:23<01:01,  4.72s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 57/69 [04:28<00:56,  4.71s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 58/69 [04:32<00:51,  4.71s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 59/69 [04:37<00:47,  4.71s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 60/69 [04:42<00:42,  4.71s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 61/69 [04:46<00:37,  4.72s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 62/69 [04:51<00:33,  4.72s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 63/69 [04:56<00:28,  4.72s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 64/69 [05:01<00:23,  4.72s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 65/69 [05:05<00:18,  4.72s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 66/69 [05:10<00:14,  4.72s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 67/69 [05:15<00:09,  4.72s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 68/69 [05:19<00:04,  4.72s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [05:24<00:00,  4.72s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [05:24<00:00,  4.71s/it]
INFO: Inference complete
